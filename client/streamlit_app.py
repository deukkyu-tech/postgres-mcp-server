import streamlit as st
import asyncio
import nest_asyncio
import os
import time
import aiohttp
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

# ì¤‘ë³µ ì´ë²¤íŠ¸ ë£¨í”„ ë°©ì§€
nest_asyncio.apply()

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# ì œëª©
st.title("ğŸ§  LangChain MCP Agent")

# ì´ˆê¸° ì„¸ì…˜ ìƒíƒœ
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [
        SystemMessage(content="ëª¨ë“  ì‘ë‹µì€ í•œêµ­ì–´ë¡œ í•´ ì£¼ì„¸ìš”.")
    ]

# ğŸ”„ ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
    # ì´ˆê¸°í™” ì‹œ ê¸°ì¡´ ëŒ€í™” íˆìŠ¤í† ë¦¬ì™€ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì´ˆê¸°í™”
    st.session_state.chat_history = [
        SystemMessage(content="ëª¨ë“  ì‘ë‹µì€ í•œêµ­ì–´ë¡œ í•´ ì£¼ì„¸ìš”.")
    ]
    st.session_state.llm_history = []  # LLMì—ê²Œ ì „ë‹¬í•  ëŒ€í™” ë‚´ìš©ë„ ì´ˆê¸°í™”
    st.rerun()  # í˜ì´ì§€ ìƒˆë¡œ ê³ ì¹¨

# âœ… SSE ì„œë²„ ìƒíƒœ í™•ì¸ í•¨ìˆ˜
async def is_sse_server_healthy(url: str):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=3) as resp:
                if resp.status == 200 and resp.headers.get("content-type", "").startswith("text/event-stream"):
                    return True
    except Exception:
        pass
    return False

# â³ ì—ì´ì „íŠ¸ í˜¸ì¶œ í•¨ìˆ˜
async def ask_agent(full_messages):
    model = ChatOpenAI(model="gpt-4o", openai_api_key=openai_api_key)
    system_msg = full_messages[0:1]
    dialogue = full_messages[1:]
    recent_dialogue = dialogue[-5:]
    trimmed_messages = system_msg + recent_dialogue

    with st.expander("ğŸ“„ ìµœì¢… ë©”ì‹œì§€ (ë””ë²„ê¹…)", expanded=False):
        st.write(trimmed_messages)

    # âœ… MCP ì„œë²„ ëª©ë¡
    servers = {
        "pg-mcp-server": "http://mcp-server:8000/sse",
        "backup-mcp-server": "http://mcp-server-2:8000/sse"
    }

    # âœ… ì‚´ì•„ìˆëŠ” MCP ì„œë²„ë§Œ ì„ íƒ
    available_servers = {}
    for name, url in servers.items():
        st.write(f"â±ï¸ {name} ì—°ê²° ì‹œë„ ì¤‘...")
        if await is_sse_server_healthy(url):
            available_servers[name] = {"url": url, "transport": "sse"}
            st.write(f"âœ… {name} ì—°ê²° ì„±ê³µ")

    if not available_servers:
        st.error("âŒ MCP ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return AIMessage(content="ëª¨ë“  MCP ì„œë²„ê°€ ë‹¤ìš´ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    try:
        async with MultiServerMCPClient(available_servers) as client:
            agent = create_react_agent(model, client.get_tools())
            start = time.time()
            res = await agent.ainvoke({"messages": trimmed_messages})
            st.write("â±ï¸ ì—ì´ì „íŠ¸ ì‘ë‹µ ì‹œê°„:", time.time() - start)

            with st.expander("ğŸ§ª ì—ì´ì „íŠ¸ ì‘ë‹µ êµ¬ì¡° (ë””ë²„ê¹…)", expanded=False):
                st.json(res)

            if 'messages' in res:
                for message in reversed(res['messages']):
                    if isinstance(message, AIMessage):
                        return message

            return AIMessage(content="ì‘ë‹µì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.error("âŒ MCP í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜ ë°œìƒ")
        with st.expander("ğŸ”§ ì—ëŸ¬ ìƒì„¸ ì •ë³´", expanded=False):
            st.exception(e)
        return AIMessage(content="MCP ì„œë²„ì— ì—°ê²° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
# ğŸ’¬ ì±„íŒ… UI: ì´ì „ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
for msg in st.session_state.chat_history:
    if isinstance(msg, HumanMessage):
        with st.chat_message("user"):
            st.markdown(msg.content)
    elif isinstance(msg, AIMessage):
        with st.chat_message("ai"):
            st.markdown(msg.content)

# ğŸ“¥ ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.chat_history.append(HumanMessage(content=user_input))

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    with st.chat_message("user"):
        st.markdown(user_input)

    # ë¹„ë™ê¸° AI ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜
    async def process_ai_response():
        # AI ì‘ë‹µ ìƒì„± ëŒ€ê¸°
        ai_msg = await ask_agent(st.session_state.chat_history)

        # ì‘ë‹µ ë©”ì‹œì§€ ì„¸ì…˜ì— ì €ì¥
        st.session_state.chat_history.append(ai_msg)

        # AI ì‘ë‹µì„ ì¶œë ¥
        return ai_msg.content  # ì—¬ê¸°ì— ì‘ë‹µ ë‚´ìš©ì„ ë°˜í™˜

    # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
    loop = asyncio.get_event_loop()
    ai_msg_content = loop.run_until_complete(process_ai_response())  # ëŒ€ê¸° í›„ ê²°ê³¼ ë°›ê¸°

    # AI ë©”ì‹œì§€ ì¶œë ¥
    with st.chat_message("ai"):
        st.markdown(ai_msg_content)  # ë¹„ë™ê¸° ì‘ì—…ì´ ëë‚œ í›„ì— ì¶œë ¥
